import streamlit as st
import time
import os
from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility

os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
os.environ['HF_HOME'] = './hf_cache' 

# æ›´æ–°åçš„é…ç½®
from config import (
    DATA_FILE, EMBEDDING_MODEL_NAME, GENERATION_MODEL_NAME, TOP_K,
    MAX_ARTICLES_TO_INDEX, COLLECTION_NAME, MILVUS_HOST, MILVUS_PORT,  # æ·»åŠ æ–°çš„é…ç½®é¡¹
    id_to_doc_map, INDEX_PARAMS, SEARCH_PARAMS, VECTOR_DIM  # ç¡®ä¿æ–°å¢å‚æ•°è¢«å¯¼å…¥
)
from data_utils import load_data
from models import load_embedding_model, load_generation_model
from rag_core import generate_answer

# --- åˆå§‹åŒ–Milvusè¿æ¥ ---
def get_milvus_client():
    try:
        connections.connect(host="localhost", port="19530")
        return True
    except Exception as e:
        st.error(f"è¿æ¥Milvuså¤±è´¥: {str(e)}")
        return False

# --- åˆ›å»ºé›†åˆ ---
def setup_milvus_collection():
    try:
        # æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨
        if not utility.has_collection(COLLECTION_NAME):
            # 1. å®šä¹‰å­—æ®µ
            fields = [
                FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
                FieldSchema(name="title", dtype=DataType.VARCHAR, max_length=500),
                FieldSchema(name="abstract", dtype=DataType.VARCHAR, max_length=5000),
                FieldSchema(name="vector", dtype=DataType.FLOAT_VECTOR, dim=VECTOR_DIM)
            ]
            
            # 2. åˆ›å»ºé›†åˆ
            schema = CollectionSchema(fields, description="åŒ»ç–—æ–‡æ¡£æ£€ç´¢é›†åˆ")
            collection = Collection(COLLECTION_NAME, schema)
            
            # 3. åˆ›å»ºç´¢å¼•ï¼ˆå…³é”®ä¿®æ”¹ç‚¹ï¼‰
            index_params = {
                "index_type": INDEX_PARAMS["index_type"],
                "metric_type": INDEX_PARAMS["metric_type"],
                "params": INDEX_PARAMS["params"]
            }
            collection.create_index(
                field_name="vector",
                index_params=index_params
            )
            
            # 4. ç¡®ä¿ç´¢å¼•åˆ›å»ºå®Œæˆ
            if len(collection.indexes) == 0:
                raise RuntimeError("ç´¢å¼•åˆ›å»ºå¤±è´¥")
                
            st.success(f"é›†åˆ {COLLECTION_NAME} åˆ›å»ºæˆåŠŸ")
            return True
            
        else:
            # å¤„ç†å·²å­˜åœ¨é›†åˆçš„æƒ…å†µ
            collection = Collection(COLLECTION_NAME)
            
            # æ£€æŸ¥ç´¢å¼•æ˜¯å¦å­˜åœ¨
            if len(collection.indexes) == 0:
                st.error(f"é›†åˆ {COLLECTION_NAME} å­˜åœ¨ä½†æ²¡æœ‰ç´¢å¼•")
                utility.drop_collection(COLLECTION_NAME)
                return setup_milvus_collection()  # é€’å½’è°ƒç”¨
            
            collection.load()
            st.success(f"æˆåŠŸåŠ è½½é›†åˆ: {COLLECTION_NAME}")
            return True
            
    except Exception as e:
        st.error(f"æ“ä½œå¤±è´¥: {str(e)}")
        return False

# --- ç´¢å¼•æ•°æ® ---
def index_data_if_needed(data, embedding_model):
    collection = Collection(COLLECTION_NAME)
    if collection.num_entities == 0:
        st.info("å¼€å§‹ç´¢å¼•æ•°æ®...")
        batch_size = 100
        total = min(MAX_ARTICLES_TO_INDEX, len(data))
        
        for i in range(0, total, batch_size):
            batch = data[i:i+batch_size]
            texts = [f"{doc['title']} {doc['abstract']}" for doc in batch]
            
            # ç”Ÿæˆå‘é‡
            embeddings = embedding_model.encode(texts, show_progress_bar=False)
            
            # å‡†å¤‡æ’å…¥æ•°æ®
            entities = [
                [doc['title'] for doc in batch],
                [doc['abstract'] for doc in batch],
                embeddings.tolist()
            ]
            
            # æ’å…¥æ•°æ®
            mr = collection.insert(entities)
            
            # ç»´æŠ¤IDæ˜ å°„
            for doc_id, doc in zip(mr.primary_keys, batch):
                id_to_doc_map[doc_id] = doc
            
        collection.flush()
        st.success(f"æˆåŠŸæ’å…¥ {total} ç¯‡æ–‡æ¡£")
        return True
    return True

# --- æœç´¢æ–‡æ¡£ ---
def search_similar_documents(query, embedding_model, top_k=TOP_K):
    collection = Collection(COLLECTION_NAME)
    collection.load()
    
    # ç”ŸæˆæŸ¥è¯¢å‘é‡
    query_embedding = embedding_model.encode([query]).tolist()[0]
    
    # æ‰§è¡Œæœç´¢
    search_params = SEARCH_PARAMS
    results = collection.search(
        data=[query_embedding],
        anns_field="vector",
        param=search_params,
        limit=top_k,
        output_fields=["title", "abstract"]
    )
    
    # å¤„ç†ç»“æœ
    ids = []
    distances = []
    docs = []
    for hits in results:
        for hit in hits:
            ids.append(hit.id)
            distances.append(hit.distance)
            docs.append({
                "title": hit.entity.get("title"),
                "abstract": hit.entity.get("abstract")
            })
    return ids, distances, docs

# --- Streamlit UI ---
st.set_page_config(layout="wide")
st.title("ğŸ“„ åŒ»ç–— RAG ç³»ç»Ÿ (Milvus Standalone)")
st.markdown(f"ä½¿ç”¨ Milvus Standalone, `{EMBEDDING_MODEL_NAME}`, å’Œ `{GENERATION_MODEL_NAME}`ã€‚")

# åˆå§‹åŒ–è¿æ¥
if get_milvus_client():
    if setup_milvus_collection():
        # åŠ è½½æ¨¡å‹
        embedding_model = load_embedding_model(EMBEDDING_MODEL_NAME)
        generation_model, tokenizer = load_generation_model(GENERATION_MODEL_NAME)
        
        if embedding_model and generation_model and tokenizer:
            pubmed_data = load_data(DATA_FILE)
            
            if pubmed_data:
                indexing_successful = index_data_if_needed(pubmed_data, embedding_model)
                
                st.divider()
                
                if indexing_successful:
                    query = st.text_input("è¯·æå‡ºå…³äºå·²ç´¢å¼•åŒ»ç–—æ–‡ç« çš„é—®é¢˜:", key="query_input")
                    
                    if st.button("è·å–ç­”æ¡ˆ") and query:
                        start_time = time.time()
                        
                        with st.spinner("æ­£åœ¨æœç´¢ç›¸å…³æ–‡æ¡£..."):
                            ids, distances, docs = search_similar_documents(query, embedding_model)
                        
                        if not ids:
                            st.warning("æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£")
                        else:
                            st.subheader("æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡æ–‡æ¡£:")
                            for i, doc in enumerate(docs):
                                with st.expander(f"æ–‡æ¡£ {i+1} (è·ç¦»: {distances[i]:.4f}) - {doc['title'][:60]}"):
                                    st.write(f"**æ ‡é¢˜:** {doc['title']}")
                                    st.write(f"**æ‘˜è¦:** {doc['abstract']}")
                            
                            st.divider()
                            
                            with st.spinner("æ­£åœ¨ç”Ÿæˆç­”æ¡ˆ..."):
                                answer = generate_answer(query, docs, generation_model, tokenizer)
                                st.subheader("ç”Ÿæˆçš„ç­”æ¡ˆ:")
                                st.write(answer)
                            
                            st.info(f"æ€»è€—æ—¶: {time.time()-start_time:.2f}ç§’")

# ä¾§è¾¹æ ä¿¡æ¯
st.sidebar.header("ç³»ç»Ÿé…ç½®")
st.sidebar.markdown(f"**Milvus åœ°å€:** {MILVUS_HOST}:{MILVUS_PORT}")
st.sidebar.markdown(f"**å‘é‡ç»´åº¦:** {VECTOR_DIM}")
st.sidebar.markdown(f"**ç´¢å¼•å‚æ•°:** `{INDEX_PARAMS}`")
st.sidebar.markdown(f"**æœç´¢å‚æ•°:** `{SEARCH_PARAMS}`")